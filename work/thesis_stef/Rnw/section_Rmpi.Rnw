\subsection{The Rmpi package}

The Message Passing Interface (MPI) is a set of library interface
standards for message-passing and there are many implementations using
these standards (see also section \cite{sec:MPI}).
Rmpi is an interface to MPI (\cite{yu06Rmpi}). As of the time of this writing Rmpi uses
the LAM implementation of MPI. For process spawning the standard
MPI-1.2 is required which is available in the LAM/MPI (version 7.1.3)
as LAM/MPI supports a large portions of the MPI-2 standard. There are
a lot of low-level interface functions to the MPI C-library available.
Furthermore, a handful of high-level functions are supplied by the Rmpi package.

A windows implementation of this package (which uses MPICH2)
can also be obtained, but the Microsoft operating system is not in the
scope of this thesis.

\subsubsection{Initializing and Status queries}

The LAM/MPI environment has to be booted prior to using any
message-passing library functions. One possibility is to use the
command line, the other is to load the Rmpi package. It automatically
sets up a (small--1 host) LAM/MPI environment (if the executables are
in the search path). 

When using the Sun Grid Engine (SGE) to boot the LAM/MPI parallel
environment the developer is not engaged with
setting up and booting the environment anymore (see
appendix \ref{app:gridengine} on how to do this). On a cluster of
workstations this is the method of choice. 


Rmpi management and query functions:

\begin{description}
\item[\texttt{lamhosts()}] finds the hostname associated with its node
  number.

%% ToDo
 
\item[\texttt{.PVM.add.hosts(hosts)}] takes a vector of hostnames to
  be added to the current virtual machine. The syntax of the
  hostnames is similiar to the lines of a pvmd hostfile (for details
  see the man page of \textit{pvmd3}). 
\item[\texttt{.PVM.del.hosts()}] simply deletes the given hosts from
  the virtual machine configuration.
\item[\texttt{.PVM.halt()}] shuts down the entire PVM system and exits
  the current R session.
\end{description}
  
It is better to use the Sun Grid Engine (SGE) to boot the PVM parallel
environment as the developer is not engaged with
setting up and booting the environment anymore (see
appendix \ref{app:gridengine} on how to do this).


\textbf{Example:} Query status of PVM \newline
running on cluster@WU using the node.q -- the parallel environment was
started with SGE using 8 nodes

<<echo=TRUE>>=
library("rpvm")
set.seed(1782)
## Query the configuration of the parallel virtual machine 
.PVM.config()
## as we have Intel core2 duo CPUs only 4 hosts are visible to PVMD

## Query the task id of this process.
mytid <- .PVM.mytid()

## Query information about the tasks running on the virtual machine
.PVM.tasks()
## only the master process is running on the PVM

## Query the status of the specified PVM process
.PVM.pstats(mytid)
.PVM.pstats(mytid+9)

## stop PVMD and exit R
.PVM.halt()

@ 


\subsubsection{Built-in high level functions}

rpvm provides two high level functions: 

\begin{description}
\item[\texttt{PVM.rapply(X, FUN = mean, NTASK = 1))}] Apply a function
  \texttt{FUN} to the rows of a matrix \texttt{X} in
  parallel using \texttt{NTASK} tasks.
\item[PVM.options(option, value)] Get or set values of libpvm options
  (for details see \cite{nali07rpvm} and \cite{geist94pvm}).
\end{description}


\textbf{Example:} Using PVM.rapply\newline
running on cluster@WU using the node.q -- the parallel environment was
started with SGE using 8 nodes

<<echo=TRUE>>=
n <- 8
X <- matrix(rnorm(n*n), nrow = n)
round(X,3)
PVM.rapply(X, sum, n)

@ 

Let us examine the function to see how parallel execution of rpvm
functions should be done. 

<<echo=TRUE>>=
PVM.rapply
@ 

The corresponding slave R script looks as follows.

<<echo=TRUE,eval=FALSE>>=
# $Id: slapply.R,v 1.2 2001/08/31 05:03:51 snake Exp $

### Slave R script for the PVM apply.
### Receive an 'order' and a matrix.  Process the matrix with apply()
### and return the resulted vector and order.

### To do: accept a string as the name of the function to be applied
### on each row.  This way, this script can be more generic. 

library (rpvm)
WORKTAG <- 22
RESULTAG <- 33

mytid  <- .PVM.mytid ()
myparent  <- .PVM.parent ()

## Receive work from parent (a matrix)
buf <- .PVM.recv (myparent, WORKTAG)

## Function to apply
func  <- .PVM.upkstr ()

cat ("Function to apply: ", func, "\n")

## Order
order <- .PVM.upkint ()
partial.work <- .PVM.upkdblmat ()

print (partial.work)

## actually work, take the mean of the rows
partial.result <- apply (partial.work, 1, func)

print (partial.result)

## Send result back
.PVM.initsend ()
.PVM.pkint (order)
.PVM.pkdblvec (partial.result)
.PVM.send (myparent, RESULTAG)

## Exit PVM
.PVM.exit ()
## Exit R
q (save="no")
@ 


New rpvm functions used in \texttt{PVM.rapply()}:

\begin{description}
\item[\texttt{.PVM.spawnR(slave, ntask = 1, ...}] spawns \texttt{ntask} copies
  of an executable or \texttt{slave} R processes. There are more
  parameters indicated by the \ldots (again I refer to \cite{nali07rpvm}). In
  PVM.rapply \texttt{NTASK} slaves sourcing ``slapply.R'' are
  spawned. The \texttt{tids} of the successfully spawned R slaves are
  returned.
\item[\texttt{.PVM.exit()}] tells the local PVM daemon that this process leaves
  the virtual machine.
\item[\texttt{.PVM.initsend()}] clears the default send buffer and
  prepares it for packing a new message.
\item[\texttt{.PVM.pkstr(data = ``'')} and \texttt{.PVM.pkint(data =
    0, stride = 1)}] are low-level correspondents of the PVM packing
    routines (see \cite{geist94pvm} for more information on packing
    data). 
\item[\texttt{.PVM.pkdblmat(data)}] packs a double matrix including
  the dimension information. There are more packing routines
  available. They are explained in \cite{nali07rpvm}.
\item[\texttt{.PVM.parent()}] returns the tid of the parent process
  that spawned the calling process.
\item[\texttt{.PVM.send(tid, msgtag)}] sends the message stored in the
  active buffer to the PVM process identified by \texttt{tid}. The
  content is labeled by the identifier \texttt{msgtag}.
\item[\texttt{.PVM.recv(tid = -1, msgtag = -1)}] blocks the process
  until a message with label \texttt{msgtag} has arrived from
  \texttt{tid}. -1 means any. The receive buffer is cleared
  and the received message is placed there instead.
\item[\texttt{.PVM.upkstr(), .PVM.upkint(), .PVM.upkdblvec()}] and other unpack data functions are
  the correspondig unpack functions to the pack functions explained above. 
\end{description}

\texttt{PVM.rapply()} takes a matrix, the function which is going to
be applied and the number of processors to use as arguments. At first
the message tags are specified. These tags are necessary to uniquely
identify messages sent in a message-passing environment. After
input validation \texttt{NTASK} child processes are spawned using the
\texttt{.PVM.spawnR()} command. After initializing the send buffer the
partitioned data (packed in the buffer using the \texttt{.PVM.pk*}
commands) is send to the corresponding child processes represented by
their task IDs using
\texttt{.PVM.send()}. PVM uses these task identifiers (TID) to
address pvmds, tasks, and groups of tasks within a virtual machine.
Meanwhile the spawned slave processes have been idle because they wait
for input (\texttt{.PVM.receive()} is a blocking command). After
receiving data from the parent the data gets unpacked. Now the slaves
apply the given function to their part of the matrix. At last another
send is initialized to provide the results to the parent process and
the slaves are detached from the virtual machine by calling a
\texttt{.PVM.exit()}. 

\subsubsection{Other important functions}

To complete the set of important functions supplied by the rpvm
package the two more functions have to be explained:

\begin{description}
\item[\texttt{.PVM.gather(x, count = length(x), msgtag, group,
    rootginst = 0}] gathers data distributed on the nodes (x) to a
  specific process (mostly the root) into a single array. It performs
  a send of messages from each member of a group of processes. A
  specific process (the root) accumulates this messages into a single vector.
\item[\texttt{.PVM.scatter(x, count, msgtag, group, rootqinst = 0}]
  sends to each member of a group a partition of  a vector x from a
  specified member of the group (mostly the root) where \texttt{count}
  is an integer specifying the number of elements to be sent to each
  member. 
\end{description}

\subsubsection{conclusion}

The \texttt{PVM.rapply()} example shown in this section followed the Single Program
Multiple Data (SPMD) paradigm. Data is splitted into different parts
which are sent to different processes. I/O is handled by a master
process. When loading rpvm in an R session this session becomes the
master process. Slaves can easily be spawned provided that there are
working slave scripts available. A major disadvantage is that the rpvm
package only has two higher-level function. One of them can be used
for calculations. That means when using this package for HPC one has
to deal with low-level message-passing which in turn provides high
flexibility. New parallel functions can be constructed on the basis of
the provided interface.

For further interface functions supplied by the rpvm package, a more detailed
description and further examples please consult the package description
\cite{nali07rpvm}.
