\chapter{High Performance Computing and R}
\label{chap:Rhpc}
\section{Introduction}

This chapter provides an overview of the capabilities of R
(\cite{Rcore07R}) in the area 
of high performance computing. A short description of the
software package R is given at the beginning of this
chapter. Subsequently extensions to the base environment 
(so called packages) which provide high performance computation
functionality to 
R are going to be explained. Among these extensions there is the
package called \pkg{paRc}, which was developed in the course of
this thesis.

Examples shown in this chapter have been produced on cluster@WU~(see
Section~\ref{sec:hardwaresoftware} for details).  

\section{The R environment}

R is an integrated suite of software facilities for data manipulation,
calculation and graphical display. R is open source originally
developed by Ross Ihaka and Robert Gentleman
(\cite{ihaka96rld}). Since 1997 a group of scientists (the
``R Core Team'') is responsible for the development of the R-project
and has write access to the source code. R has a homepage
which can be found on \url{http://www.R-project.org}. Sources, binaries
and documentation can be obtained from CRAN, the Comprehensive R
Archive Network (\url{http://cran.R-project.org}). Among other things
R has (\cite{Rcore07R}) 
\begin{itemize}
\item an effective data handling and storage facility,
\item a suite of operators for calculations on arrays, in particular matrices,
\item a large, coherent, integrated collection of intermediate tools
  for data analysis,
\item graphical facilities for data analysis and display either
  directly at the computer or on hardcopy, and
\item a well developed, simple and effective programming language
  (called `R') which includes conditionals, loops, user defined
  recursive functions and input and output facilities. (Indeed most of
  the system supplied functions are themselves written in the R
  language.)
\end{itemize}

R is not only an environment for statistical computing and graphics
but also a freely available high-level language for programming. It
can be extended by standardized collections of code called
``packages''. So developers and statisticians around the world can
participate and provide optional code to the base R environment.
Developing and implementing new methods of data analysis can therefore
be rather easy to achieve (for more information about R and on how R can
be extended see \cite{hornik07Rfaq} and \cite{Rcore07Ext}). 


Now, as datasets grow bigger and bigger and algorithms become more and
more complex, R has to be made ready for high performance
computing. Indeed, R is already prepared through a few extensions
explained in the 
subsequent chapters. The packages mentioned in this chapter can be
obtained from CRAN except \pkg{paRc} which can be obtained from
R-Forge (\url{http://R-Forge.R-project.org}), a platform for
collaborative software development for the R community
(\cite{theussl07R-Forge}).

%% subsection: The Rmpi package 
\input{section_Rmpi.tex}

%% subsection: The rpvm package 
\input{section_rpvm.tex}

%% subsection: The snow package 
\input{section_snow.tex}

%% subsection: The paRc package 
\input{section_paRc.tex}

\section{Other Packages Providing HPC Functionality}
\label{sec:otherpackages}
There are a few other packages which supply the user with parallel
computing functionality or extend other high performance computing
packages. In this section a short description of each of these
packages is given.

\begin{description}
\item[rsprng] (\cite{li07rsprng}) is an R interface to SPRNG (Scalable
  Parallel Random 
  Number Generators---\cite{mascagni00ssl}). SPRNG is a package for parallel
  pseudo random number generation with the aim to be easy to use on a
  variety of architectures, especially in large-scale parallel Monte
  Carlo applications.
\item[rlecuyer] (\cite{sevcikova05rlecuyer}) like \pkg{rsprng}
  provides an interface to a parallel pseudo random number
  generator. \pkg{rlecuyer} is the C implementation of the  
  random number generator with multiple independent streams developed
  by \cite{l'ecuyer02RNG}.
\item[RScaLAPACK] (\cite{samatova05RSca} and \cite{yoginath05rhp})
  uses the high performance ScaLAPACK library
  (\cite{dongarra97sus})for linear algebra computations. ScaLAPACK is
  a library of high performance linear algebra routines which makes
  use of message passing to run on distributed memory machines. Among
  other routines it provides functionality to solve systems of linear equations, linear
  least squares problems, eigenvalue problems and singular value
  problems. ScaLAPACK is an acronym for Scalable Linear Algebra
  PACKage or Scalable LAPACK. \cite{samatova06hps} have shown how to
  use \pkg{RScaLAPACK} in biology and climate modelling and analyzed
  its performance.
\item[papply] (\cite{currie05papply}) implements a similar interface
  to lapply and apply but distributes the processing evenly among the
  nodes of a cluster. \pkg{papply} uses the package \pkg{Rmpi} (see
  Section~\ref{sec:Rmpi}) for
  communication but supports in addition error messages for debugging.
\item[biopara] (\cite{lazar06biopara}) allows users to distribute
  execution of large problems over multiple machines. It uses R socket
  connections (TCP) for communication. \pkg{biopara} supplies two high
  level functions, one for distributing work (represented by function
  and its arguments) among ``workers'' and the other for doing
  parallel bootstrapping like the native R function boot(). 
\item[taskPR] (\cite{samatova04taskPR}) provides a parallel execution
  environment on the basis of TCP or MPI-2.
\end{description}

\section{Conclusion}

In this chapter we have shown that R offers a lot of possibilities in
high performance computing. Extensions which interface the main
message passing environments, MPI and PVM, offer the highest
flexibility as parallel applications can be based upon low level
message passing routines. Especially package \pkg{Rmpi} has to be
noted as it offers interactive testing of developed parallel
functions. 

For easy parallelization of existing C code on shared memory machine a
new approach has been shown using package \pkg{paRc}. Implicit
parallel programming can be achieved using the compiler directives
offered by OpenMP. A major disadvantage is that parallel functionality
has to be implemented low level in C or FORTRAN.